# Часть 2 (Алгоритмы)
## Уровни абстракции
Пользователь наблюдает нашу систему со стороны и она для него представляется как единое целое. Он приходит на "контур", который дальше отправляет его запрос на какую-то ноду в нашем сервисе. Внутри система может состоять из разных компонент. Например, одной из частей системы может быть ZooKeeper. Нам надо уметь понимать, что мы хотим моделировать, а что нет. Лучше понять, что нам надо моделировать помогут проверяемые св-ва. Сравним существующие систему и их спеки:
* Paxos/Raft: В этих алгоритмах не используется ничего стороннего. Это самый высокий уровень детализации. Мы хотим полностью описать, как ведут себя участники алгоритмов, их протокол взаимодействия и проблемы, с которыми они сталкиваются. В системах, где одной из составляющих является обмен сообщениями по сети надо уметь моделировать асинхронность сети. Так же в Raft моделируется дубликация и потеря сообщений
* Kafka: Участники репликации в Kafke используют  ZooKeeper. Мы не хотим моделировать, что происходит внутри ZooKeeper, так как полагаем, что эта система работает и надежна. Единственное место, где мы хотим описать взаимодействие реплик - это обмен сообщениями о leader election. Таким образом, авторы абстрагировались от деталей реализации ZK, так как мы считаем, что система надежна. Нода в ZK - это распределенная отказоустойчивая ячейка памяти, которую изменяют наши реплики в экшенах.
* ClickHouse: Система использует ZooKeeper для всех распределенных алгоритмов: Выборы лидера, репликация и др. Обмен сообщениями между репликами происходит только по отправке данных в репликации. Можем считать, что система получила кусок данных тогда, когда обработало информацию о вставке в ZK. Это самый высокий уровень абстракции, так как мы моделируем систему только такой, как ее видит пользователь.

## Моделирование сети
Когда в системе используется обмен сообщениями, то важно моделировать проблемы, с которыми система может столкнуться. Так как система асинхронная, то мы не можем сказать, когда сообщения будут доставлены и в каком порядке. Сеть является одним из важных участников нашего алгоритма и нам надо учитывать ее в нашей спеке.

* Самое главное надо смоделировать все сообщения, которые существуют в системе (находятся в "проводах" или доставляются до ноды) для этого в TLA используется set, который помогает обеспечить недетерминизм в нашей системе. Конструкция \E val \in set: P(val). Выдает не самый первый элемент, который удовлетворяет предикату P, а выдает какой-то. Следовательно, это помогает моделировать reordering на отправленных сообщениях и их задержку. Например, в [Raft-е](https://github.com/ongardie/raft.tla/blob/34cdd49d22615426ea00a6605b95be57b3cab49a/raft.tla#L306) при получении сообщения проверяется в каком term-е оно было отправлено, чтобы не обрабатывать сообщения из прошлого.
* [Промодедлировать отправку](https://github.com/fpaxos/fpaxos-tlaplus/blob/c562667ad96bcb9e07a30417a45b49c5d21d1fbe/FPaxos.tla#L25) сообщений можно просто экшеном, который добавит его в set. Но, нам нужно уметь моделировать отправку сообщения всем участникам системы или только кому-то определенному. В Paxos для этого убрали адресатов, таким образом, это сообщение могут получить все acceptor-ы. Или мы можем явно указывать кому и от кого пришло сообщение, как это сделано в [Raft-e](https://github.com/ongardie/raft.tla/blob/34cdd49d22615426ea00a6605b95be57b3cab49a/raft.tla#L306)
* Логика отправки сообщения может быть простой (мы просто добавляем сообщение в set, таким образом set только увеличивается и никогда не уменьшается, так как нам страшно, что могут быть обработаны некоторые сообщения повторно) или наши сообщения после обработки могут удаляться из set. В таком случае  наше сообщение не будет обработано повторно. Таким образом, мы сразу отказываемся рассматривать некоторые проблемы сети (удаление сообщений и дубликация). Нам надо самим добавить экшены, которые будут моделировать такие ситуации. Так сделали в [Raft](https://github.com/ongardie/raft.tla/blob/34cdd49d22615426ea00a6605b95be57b3cab49a/raft.tla#L438)

## Сбои
Наша система должны быть как можно ближе к реальности. В большинстве распределенных систем ноды не могут жить вечно. Они могут выходить из строя навсегда, долго не отвечать и т.д. В асинхронной системе у нас нет возможности отличить умершую ноду и ту, которая долго обрабатывает наш запрос. Надо ли нам моделировать падение сервера в нашей спеке?

Первым делом надо понять, что такое умершая нода в рамках TLC.
Мы описываем состояния, в которых наша система может прибывать, и переходы между ними. TLC строит автомат поверх этого и исследует его. Получается граф, где вершины - это состояние нашей системы, а ребра - это переходы между ними (доставка сообщения или срабатывания таймаута). Выполнение нашей системы - это путь в этом автомате из стартовой конфигурации в конечную (Иногда конечной конфигурации может не быть, то есть состояний системы б.м., но от этого стараются отойти, чтобы проверять св-ва). Это очень похоже на док-во FLP. Там аналогично строится граф поверх системы. В док-ве FLP  нигде не рассматриваются отказы системы, авторы утверждают, что они не отличают умершую ноды от той, которая работает очень медленно из-за асинхронной модели сети, где невозможно дать никаких гарантий на время работы.

Что же такое отказ ноды в рамках графа конфигураций? Мы аналогично док-ву FLP не будет отличать медленные и умершие ноды. У нас есть экшены, которые зависят от состояния участников, так как TLC исследует все возможные траектории в нашем графе, то чекер проверит траектории, где экшены, связанные с работой ноды, могли быть никогла не выбраны. Следовательно, в работе системы не будет участвовать один из участников, что аналогично смерти узла.

Аналогично TLC моделирует ноды, которые рестартовали после сбоя и опять приняли участие в работе алгоритма. Чекер просто исследует траекторию, где в какой-то момент будет взят экшен, связанные с рестартанувшей нодой.

ПОЧЕМУ НЕ ГОВОРИМ ПРО ВИЗАНТИЙСКИЕ ОТКАЗЫ?

НО, иногда можно моделировать сбои участника. Например, таймауты.

## Concurrency (pron)

##
