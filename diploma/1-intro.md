# Часть 1 (Intro)
## Корректность распределнных систем
### Распределенные системы
Распределенные системы - это ключевой компонент систем хранения и обработки данных и современных масштабируемых сервисов.

Например:
* DynamoDB используется для реализации shopping card в Amazon.
* Big Table используется в Gmail
* Percolator используется для создания поискового индекса в Google

###
Если эти компоненты будут реализованы неправильно, то это может привести к неожиданным последствия для пользователя. Например: потеря данных в хранилище.

### Сложно писать код
Написать корректный код для такого рода систем намного сложнее, так как надо учитывать множество факторов, которые могут влиять на алгоритм (параллельность, потеря сообщений, отказ узлов и т.д.). Из-за этого одной из главных проблем для таких сервисов является тестирование.

### Стандартные методы
В индустрии используются несколько стандартных техник для проверки, что система соответствует набору требований: например, если система подтвердила запись данных, то она не может их потерять:
* Стандартное тестирование - разработчики пишут множество тестов, которые новый код должен пройти, прежде чем его добавят в кодовую базу.
* Код ревью - после прохождения всех рукописных тестов разработчики пытаются найти баги с помощью просмотра нового кода.
* Дизайн ревью - разработчики описывают компоненты системы и их взаимодецйствие.

### Проблемы техник
Но эти техники не подохдят для распределенных систем, так как человек является ключевым звеном в каждом из них, а он не способен промоделировать у себя в голове все выполнения и может что-то упустить.

Эту мысль подтверждают инженеры из Amazon: "We use deep design reviews, code reviews, static code analysis, stress testing, fault-injection testing, and many other techniques, but we still find that subtle bugs can hide in complex concurrent fault-tolerant systems. One reason for this problem is that human intuition is poor at estimating the true probability of supposedly ‘extremely rare’ combinations of events in systems operating at a scale of millions of requests per second ..."

Есть рандомизированные подохды к тестированию, например: fault injection. Они основаны на внедрение в код неисправностей, которые срабатывают в произвольные моменты времени. Например: переключение потоков при тестировании многопоточных алгоритмов. Одной из реализаций такого подхода является фреймворк Jepsen, который помог найти баги в Cassandra, FaunaDB, Kafka и других.

C помощью этих методов разработчики пытаются покрыть как можно больше нетривиальных поведений. Но эти техники тестирования статистически не могут проверить очень редкие баги.

"We have found that testing the code is inadequate as a method to find subtle errors in design, as the number of reachable states of the code is astronomical. So we looked for a better approach."

## Формальный методы
Тот самый лучший подохд для верификации сложных систем - это формальные методы.

### ФВ
Формальная верификация - это построение логической модели системы и ее анализ средствами математической логики. Этот метод фокусируется на том, что должна делать система, а не как (в отличие от языков программирования).

Основные понятия, которыми оперирует формальная верификация:
* Автомат (State Machine) – некоторое изменяющееся во времени состояние, которое описывается набором переменных
* Состояние автомата / системы - назначение значений этим переменным
* Поведение (Behavior) / траектория – бесконечная последовательность состояний
* Спецификация (Specification) – декларативное описание поведения системы (состояний и переходов)

Для каждой системы разработчики описывают свойства, которым она должна удовлетворять. Для формальной верификации Свойства (Property) – логические формулы, которые интерпретируются на траекториях, т.е. последовательностях состояний.

Model checker перебирает все возможные состояний системы и проверяет в каждом из них свойства.

Одной из самых популярных реализаций такого подхода является язык TLA+ и TLC - model checker для него.

TLA+ - это язык формальной спецификации, который основан на нетипизированная теории множеств, логике первого порядка и временной логике, которую называют TLA. TLA - это темпоральная логика, с помощью которой можно описать распределенные и многопоточные системы/алгоритмы.

Типичная спецификация для формальной верификации на TLA+ выглядит как: Spec == Init /\ []Next
* Init - initial-state predicate. Формула, которая верна для всех начальных состояний
* Next - отношение следующего состояния. Является дизъюнкцией нескольких действий и описывает все возможные следующие действия

TLA+ использует логику LTL. Это язык линейного времени. Последовательность описывает одно выполнение нашей системы. Есть другая логика - CTL. Где рассматривается не одно выполнение, а целое множество их. В нем утверждения формулируются о нескольких исполнениях сразу, а в LTL мы формулируем свойство для одного какого-то исполнения. Была выбрана эта модель, так как нас интересуют высказывания про отдельные исполнения, а не про несколько сразу, так как свойств таких не возникает в распределенных системах.

Примеры:
* Свойство для SI

    FirstCommitterWins ==
        (* There are no committed transactions that were concurrent, and whose write-sets (keys) intersect. *)
        ~ \E t1, t2 \in CommittedTxns(history) :
            /\ t1 /= t2
            /\ AreConcurrent(history, t1, t2)
            /\             KeysThatTxnHasDoneOperationOn(history, t1, "write")
                \intersect KeysThatTxnHasDoneOperationOn(history, t2, "write")
                    /= {}

* Свойство алгоритма Paxos

    SafeValue == \A v \in Value: \A b \in Ballot: Agreed(v,b) => NoFutureProposal(v,b)

Cам по себе TLA+ не оперирует никакими понятиями из мира распределенных систем, это логический ассемблер, использующий логику первого порядка и темпоральную логику. Но Лэмпорт намеренно выстраивал его таким образом, чтобы на него удобно укладывались распределенные алгоритмы.

### Как матчить спеку и алгоритм

Общая схема представления распределенной системы в рамках TLA+:

Вершины в графе состояний отвечают “снимку” всей системы, они образованы состоянием всех реплик в системе и состоянию сети

Переходы между состояниями соответствуют реакции узлов на события, а именно получение сообщений / запросов или операций от клиента

Таким образом TLC исследует граф конфигураций системы и проверяет его на выполнение свойствам.

На стадии создания алгоритма/системы, TLA+ помогает правильно спроектировать компонент. Если в дизайне системы допущена ошибка, то и в коде она тоже будет допущена. Так же формальное описание системы помогает лучше понять алгоритм, который реализован.

Хорошее введение в TLA+ - книга Practical TLA и видеокурс Лесли Лампорта. А для продолжения - Specifying Systems Лесли Лампорта.

## TLA+ в индустрии
Изначально TLA+ был разработан Лесли Лампортом в 1999 году как инструмент для спецификации собственных алгоритмов и использования только лишь в академических кругах.

Интерес со стороны индустрии начался со статьи “Use of Formal Methods at Amazon Web Services”, где инженеры Amazon Web Services поделились своим опытом применения формальных методов. Они использовали TLA+ для верификации критичеси важных для облачной инфраструктуры алгоритмов. Например: локфри алгоритмы, протоколы репликации и переконфигурации, протоколы взаимодействия по сети.

![result](res.png)

Сейчас IT гиганты используют TLA+ для верефикации своих сервисов:
* Microsoft Azure - с помощью TLA+ верифицировали модели согласованности в CosmosDB
* Yandex - с помощью TLA+ нашли багу в LF аллокаторе. В управлении памятью в LF стеке не была учтена A-B-A проблема.
* Elastic - c помощью TLA+ верифицировали сам алгоритм поиска и протокол репликации данных.

## ClickHouse
В данной работе мы применим TLA+ для сепицификации и верификации механизма репликации еще одной распределенной системы - ClickHouse.

ClickHouse - столбцовая система управления базами данных (СУБД) для онлайн обработки аналитических запросов (OLAP). Которая разрабатывается Яндексом и open-source сообществом.

ClickHouse работает с таблицами, которые можно горизонтально масштабировать с помощью шардирования. Для отказоустойчивости каждый шард в КХ можно независимо реплицировать с помощью ZooKeeper-а.

## План работы
В главе 1 будут описаны принципы спецификации распределенных систем с помощью TLA+:
* Как выбрать нужный уровень детализации для системы/алгоритма
* Надо ли моделировать сбои в спеках
* Как моделировать сеть в алгоритмах, где используется взаимодействие через отправку сообщений между узлами
* Каким образом TLA+ позволяет описать недетерминизм, который возникает в системе.

В главе 2 пойдет речь об инженерных аспектах формальной верификации:
* Как протестировать саму спецификацию
* Как сократить число состояний в графе конфигураций
* Какие выбрать подходящий режим у model checker-а.

Для ответов на эти вопросы мы будем использовать существующие спецификации систем хранения / обработки данных и алгоритмов репликации. Выбор именно этих спек заслуживает комментариев:
* Apache Kafka - протокол репликации партиции в распределенной персистентной очереди сообщений, уоторый используется в Netflix, Twitter. В этой системе узлы обмениваются сообщениями и взаимодействуют через ZooKeeper.
* Snapshot Isolation - алгоритм изоляции транзакций, работающий поверх мультиверсионного хранилища данных. Эта спеки интересна тем, что тут моделируются не узлы алгоритма, а сущности, с которыми работает клиент
* Percolator - клиентский протокол распределенных транзакций поверх распределенного k/v хранилища BigTable, используется для cross-row транзакций в веб-индексаторе Google.
* Single Decree Paxos - протокол распределенного консенсуса, который лежит в основе механизма репликации шардов (таблетов) в системе Google Spanner. Этот алгорит живет полностью в модели message passing, поэтому авторы спеки должны промоделировать всех участников системы.
* Raft - RAFT - протокол репликации лога команд, современный аналог Paxos. Применяется в MongoDB, InfluxDB и ETCD.

В главе 3 мы применим все разработанные приему для формальной спецификации и верификации протокола репликации в распределенной аналитической базе данных ClickHouse. Основная задача состоит в формальном описании алгоритма репликации КХ и верификации алгоритма обрезки лога в ZooKeeper и для кворумных вставок и чтений в КХ.
