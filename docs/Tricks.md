## +Cal/TLA+
### Когда надо выбрать TLA+?
* В большинстве распределенных алгоритмов
* В алгоритме участвует среда
* Нам не надо моделировать процессы ([SI](https://github.com/will62794/snapshot-isolation-spec))
* Нам не нужна привязка к id процессов (Например, проверка Linearizability)

### Когда надо бырать +Cal?
* В большинстве параллельных алгоритмов
* В проверяемых св-вах участвуют id процессов

# Факты и приемы
## TLA+ (как язык)
### Моделирование обмена сообщениями
-------------------------------------
#### Raft
Явно моделируем отправку сообщений. Для этого поддреживаем [все сообщения](https://github.com/ongardie/raft.tla/blob/34cdd49d22615426ea00a6605b95be57b3cab49a/raft.tla#L32)
В сообщение указывается Term в котором оно было отправлено и при получении смотрим, что оно меньше текущего.

#### Paxos
Есть [set](https://github.com/fpaxos/fpaxos-tlaplus/blob/c562667ad96bcb9e07a30417a45b49c5d21d1fbe/FPaxos.tla#L25) всех сообщений. Сет описывает все сообщения, которые сейчас есть в нашей системе(проводах и т.п.).

Для отсылки сообщения происходит просто добавление его в set. Мы явно [задаем](https://github.com/fpaxos/fpaxos-tlaplus/blob/c562667ad96bcb9e07a30417a45b49c5d21d1fbe/FPaxos.tla#L13) типы сообщений, которыми могут обмениваться ноды.
Сет делает доставку сообщение до нод асинхронной(?), как в настоящей системе.

Можно заметить, что в спеке в фазе Prepare у сообщений [нет адресата](https://github.com/fpaxos/fpaxos-tlaplus/blob/c562667ad96bcb9e07a30417a45b49c5d21d1fbe/FPaxos.tla#L37) так мы посылаем сообщением всем асепторам разом.
А в фазе Accept у сообщения уже есть адресат. Надо для того, чтобы понимать, что acceptor находится в кворуме текущем.

#### Kafka
Есть shared memory(зукипер). Отправка сообщений моделируется только в одном месте. Когда мы обновляем isr
Это моделируется момент, когда реплика получает сообщение о том, что она лидер, но но сообщение может прилететть с задержкой
То есть это может стать причиной того, что у нас 2 лидера в системе.

### Моделирование сети
---------------------------------------
#### Raft
[Моделируем](https://github.com/ongardie/raft.tla/blob/34cdd49d22615426ea00a6605b95be57b3cab49a/raft.tla#L438) сбои сети
Для этого сделаны 2 экшена, которые могут дублировать сообщения или дропать их. Почему в рафте это используется: у нас есть сет всех сообщений и, когда мы обрабатываем сообщение, то мы его удаляем из сета или долбавляем. Усложняет жинзь
#### Kafka
* Сеть моделирует set ISR
* Сет только увеличивается
* У сообщений есть эпохи, которые показывают, что мы увидим, а что нет

### Честность
В TLA+ есть два вида честности: SF и WF.

_SF_ - Если событие бесконечно-часто верно, то оно должно быть выполнено. (Если есть цикл в поведение и в нем б.ч. выполнено какой-то экшен из Next, то он обязательно должен быть взят)

_WF_ - Если собитие бесконечно верно, то оно должно быть выполнено. (Если в цикле в поведении, в каждом их состояний выполнен экшен из Next, то он должен быть взят)

Применение можно найти в [Kafka](https://github.com/hachikuji/kafka-specification/blob/3cc3cf6914f76573f8b66fb700f8b90ac7ca8bed/KafkaTruncateToHighWatermark.tla#L44)
WF стоит у события выбора лидера. В спеке кафки может быть так, что лидер не будет выбран долгое время. И наша система не будет совершать прогресс.

Чтобы избежать такого "тупого" поведения, нам хочется "повысить приоритет" у действия `BecomeLeader`.

Аналогично происходит с SF. Добавляя честность мы отдаем приоритет некоторым действиям и запрещаем нашему алгоритму некоторые ненужные траектории.

### Заикания
Чтобы убрать заикания на одном состоянии алгоритма можно на оператор Next [навесить](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L610) честность

### Проверка св-в
Для того, чтобы наглядно задать св-ва, которые мы хотим написать можно  [воспользоваться](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L622) ? THEOREM или внести их в проверяемые св-ва в конфигурации.

### Редукция и симметрия
[model-values](https://tla.msr-inria.inria.fr/tlatoolbox/doc/model/model-values.html)

### Type Check
В TLA+ нет никаких типов. Для того, чтобы TLC во время работы проверял, что переменные принимают допустимые значения, надо
написать инфариант, который должен быть истинен в каждом состоянии. Примеры: [SI](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/serializableSnapshotIsolation.tla#L207) [Kafka](https://github.com/hachikuji/kafka-specification/blob/3cc3cf6914f76573f8b66fb700f8b90ac7ca8bed/KafkaReplication.tla#L101) [Paxos](https://github.com/fpaxos/fpaxos-tlaplus/blob/c562667ad96bcb9e07a30417a45b49c5d21d1fbe/FPaxos.tla#L27)

### Модели согласованности
* В Cosmoc для этого сделана [история](https://github.com/Azure/azure-cosmos-tla/blob/f3230bc9b717bb405ddfb9bfc005dcbd7c1aee4a/general-model/cosmos_client.tla#L231) всех операций
* Хотим записывать операцию с ее timestamp-ом
* Для проверки св-в будем сравнивать время опреации и данные в ячейках

### Моделируем процессы, события и т.п.
С помощью TLA+ можно моделировать: события(Kafka, Paxos, Raft), а можно моделировать процессы(SI(транзакции)).

## Алгоритмы

### Выборы лидера
----------------------------------------
#### Kafka


#### Raft

### Тестирование
Можно писать [юнит-тесты](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L673). Как их [проверять](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L667)

Иногда для отладки алгоритмов можно находить какое-нибудь интересное поведение. Для этого можно
написать инвариант, которому это поведение соответсвует и [проверять](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L1165), что он нарушается, тогда TLC покажет требуемое

Важно, что если мы хотим проверять liveness св-ва, то нам надо запрещать бесконечные поведения спеки.


### Сбои
Почему нет "я мертв"?
Сбои не моделируютя явно, так как мы не различаем мертвый узел и узел, который долго не отвечает

### Уточнение спеки

### Дедлоки алгоритма от дедлоков спеки (как отличать)
[Отличие дедлока алгоритма от дедлока спеки](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L885)
[Объяснение](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/textbookSnapshotIsolation.tla#L551)

Для того, чтобы TLC находил дедлок алгоритма в Next можно добавить событие, когда наш алгоритм завершился и бесконечно ходит по кругу, как в [SI](https://github.com/pron/amazon-snapshot-spec/blob/9c60cb18151889d7b4c0a4ffd7de0b6fc2db0fb2/serializableSnapshotIsolation.tla#L996)

В спеке SI существует конечное число транзакций для которых проверяется выполнение св-в. Мы хотим уметь находить дедлок алгоритма. Но TLC может сказать, что обнаружился дедлок, когда все наши транзакции будут выполнены. Мы хотим уметь различать дедлок алгоритма от конца его работы.

### Как сделать читаемым Trace
Надо писать Next в виде простой дизъюнкции ([пример](https://github.com/hachikuji/kafka-specification/blob/3cc3cf6914f76573f8b66fb700f8b90ac7ca8bed/KafkaTruncateToHighWatermark.tla#L33)).
